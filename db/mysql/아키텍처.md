# MySQL의 두뇌와 손
MySQL은 크게 `MySQL엔진(두뇌)`와 `스토리지 엔진(손)`으로 나뉩니다.
- MySQL 엔진: 쿼리를 이해하고, 최적의 실행 계획을 세우는 "두뇌"
- 스토리지 엔진: 실제로 디스크에서 데이터를 읽고 쓰는 "손"


## MySQL 엔진
### 커넥션 핸들러
```java
userRepository.findById(1)
orderRepository.save(order)
productRepository.updateStock(productId, quantity)
```
java 애플리케이션에서 다음 코드가 동시에 실행된다고 가정해보겠습니다. MySQL 서버 입장에서는 이 요청을 어떻게 구분할 수 있을까요? 또 각 요청이 트랜잭션 중인지, 어떤 DB를 사용 중인지 어떻게 알 수 있을까요? 요청들을 순선대로 처리해야 하는데, 누가 관리하나요?

이런 문제를 해결하기 위해 커넥션 핸들러가 등장했습니다. 커넥션 핸들러는 MySQL 연결마다 전담 스레드를 배정해 요청을 처리합니다.


### 쿼리 파서
커넥션 핸들러로부터 SQL 문을 전달받았습니다. 하지만 MySQL은 이 문자열을 그대로 실행할 수 없습니다.
```sql
SELECT * FROM users WHERE id = 1
```
이 문장에서 어디가 키워드이고, 어디가 테이블명이고, 어디가 조건절일까요? 문법 오류는 없을까요? 쿼리 파서는 SQL 문을 단어 단위로 분해해 트리 구조로 만듭니다. SELECT는 키워드, users는 테이블명, WHERE는 조건절... 만약 SELCT 같은 오타가 있다면 이 단계에서 걸러집니다.

### 전처리기
문법은 맞는데, 해당 테이블이 정말 존재할까요 ?
```sql
SELECT * FROM non_existing_table WHERE id = 1
```
전처리기는 실제 데이터베이스 메타데이터와 대조하며 확인합니다:
- non_existing_table 테이블이 존재하는가?
- 현재 사용자에게 이 테이블을 조회할 권한이 있는가?
- id 컬럼이 실제로 존재하는가?

### 옵티마이저
같은 결과를 얻는 방법이 한 가지만 존재할까요?
```sql
SELECT * FROM users WHERE age > 25 AND city = '서울'
```
이 쿼리를 실행하는 방법은 여러 가지입니다:
방법 1: 전체 테이블 스캔 - 모든 레코드를 읽으며 조건 확인
방법 2: age 컬럼 인덱스 사용 - age > 25인 레코드만 찾고 city 확인
방법 3: city 컬럼 인덱스 사용 - city='서울'인 레코드만 찾고 age 확인
방법 4: (age, city) 복합 인덱스 사용 - 두 조건을 동시에 만족하는 레코드만 찾기

옵티마이저는 테이블의 통계 정보(레코드 수, 인덱스, 데이터 분포)를 바탕으로 각 방법의 비용을 계산하고, "가장 저렴한" 실행 계획을 선택합니다.

### 실행 엔진
계획이 세워졌으니 이제 실행할 차례입니다. 실행 엔진은 옵티마이저가 만든 계획을 단계별로 실행합니다:
```
1단계: users 테이블에서 name='홍길동'인 레코드 조회 요청 (→ 스토리지 엔진)
2단계: 1단계 결과를 받아서 orders 테이블과 조인 요청 (→ 스토리지 엔진)
3단계: 최종 결과를 커넥션 핸들러에 반환
```
실행 엔진은 직접 데이터를 읽지 않습니다. 각 단계를 스토리지 엔진(핸들러)에게 요청하고, 받은 결과를 다음 단계의 입력으로 연결하는 조율자 역할을 합니다.

## 스토리지 엔진 (InnoDB)
실행 엔진의 요청을 받아 실제로 디스크에서 데이터를 읽고 쓰는 계층입니다. 스토리지 엔진에서 발생할 수 있는 문제 상황을 먼저 생각해보겠습니다.

### 디스크 접근은 느리다 - 버퍼 풀의 등장
```kotlin
repeat(1000) {
	userRepository.findById(1)
}
```
다음 작업을 매번 디스크에서 읽는다면 어떨까요 ? 끔찍하게 느리고 비효율적이지 않을까요 ?


쓰기 작업은 어떨까요 ?
```kotlin
UPDATE users SET name = 'Alice' WHERE id = 1;
```
UPDATE, INSERT가 필요할 때 마다 디스크 쓰기 작업이 일어나면 많은 데이터를 처리하기에는 벅차지 않을까요 ?


이런 디스크 작업의 비효율성을 해결하기 위해 MySQL에서는 `버퍼 풀`이라는 개념을 사용합니다.


```
[실행 엔진 요청] "users 테이블에서 id=1 레코드 주세요"
      ↓
[스토리지 엔진] 
  1. 버퍼 풀에서 먼저 찾기 (캐시 히트!) → 바로 반환 ✨
  2. 없으면? → 디스크에서 읽어서 → 버퍼 풀에 저장 → 반환
```

```
UPDATE users SET name = 'Alice' WHERE id = 1;
이 쿼리가 실행되면:

버퍼 풀의 페이지를 수정 (Dirty Page로 표시)
나중에 체크포인트 시점에 여러 변경사항을 모아서 일괄 처리
```

메모리는 한정적인데 어떤 데이터를 유지하고, 어떤 데이터를 버릴까요 ? 언제 변경사항을 모아서 일괄 처리할까요 ?
InnoDB는 이를 해결하기 위해 세 가지 리스트로 페이지를 효율적으로 관리합니다.

1. FREE 리스트: 아직 사용되지 않은 빈 페이지
   - 새로운 데이터를 디스크에서 읽어올 때 FREE 리스트의 페이지를 사용
2. LRU 리스트: 데이터 페이지를 사용 빈도순으로 관리
   ![image](https://rootbly-images.s3.ap-northeast-2.amazonaws.com/notes/ad9fa37df115cce386b32358beb18225.png)
   - 일반적인 LRU라면 새로 읽은 데이터를 가장 앞(MRU)에 둘 겁니다. 하지만 문제가 있습니다.
```sql
SELECT * FROM huge_log_table WHERE created_at < '2024-01-01';
```
다음과 같은 배치 작업으로 테이블 스캔을 해버리면 핫 데이터가 캐시에서 전부 밀려나버립니다.

이를 해결하기 위해 새로 읽은 페이지를 OLD영역에 넣습니다.
- 자주 조회되면 MRU로 승격
- 그렇지 않으면 자연스럽게 삭제


3. FLUSH 리스트: 메모리에서 변경되었지만 아직 디스크에 쓰지 않은 Dirty Page 목록
   - 체크포인트나 플러시 시점에 FLUSH 리스트의 Dirty Page들을 디스크에 일괄 변경합니다.


#### 인덱스 수정도 느리다 - 체인지 버퍼의 등장
다음 쿼리를 실행하면 인덱스도 수정되어야 합니다.
```sql
INSERT INTO orders (user_id, product_id, amount) VALUES (100, 200, 50000);
```
이 INSERT를 실행하면:
1. orders 테이블의 데이터 페이지 수정
2. user_id 인덱스 페이지 수정
3. product_id 인덱스 페이지 수정

인덱스 페이지가 버퍼 풀에 없다면?
- 디스크에서 인덱스 페이지를 읽어와야 합니다 (랜덤 I/O 발생)
- 여러 개의 인덱스가 있다면? 여러 번의 랜덤 I/O 발생

이를 해결하기 위해 InnoDB에서는 인덱스를 바로 수정하지 않고 체인지 버퍼라는 임시 공간에 변경 사항만 기록해둡니다.
```
[INSERT 실행]
    ↓
[데이터 페이지] 즉시 수정 (버퍼 풀)
    ↓
[체인지 버퍼] "user_id 인덱스에 100 추가 예정"
              "product_id 인덱스에 200 추가 예정"
    ↓
[나중에 백그라운드에서]
인덱스 페이지를 읽을 때 체인지 버퍼의 변경사항을 합침 (Merge)
```

**장점**:
- 인덱스 수정을 위한 랜덤 I/O를 지연시킴
- 여러 변경사항을 모아서 한 번에 처리 (I/O 횟수 감소)
- INSERT/UPDATE/DELETE 성능 향상

**언제 머지될까요?**:
- 해당 인덱스 페이지가 버퍼 풀로 읽혀질 때
- 백그라운드 스레드가 주기적으로 머지할 때
- 체인지 버퍼가 가득 찰 때

#### B-Tree 탐색도 반복하면 느리다 - 어댑티브 해시 인덱스의 등장
MySQL의 기본 인덱스는 B-Tree입니다. 범위 조회에 강하고 조회가 빠르지만, 같은 값으로 반복 조회하는 경우에도 매번 루트 노드 → 중간 노드 → 리프 노드 탐색을 반복해야 합니다.
```kotlin
repeat(10000) { 
	liveRoomRepository.findById(100) // 매번 B-Tree 탐색! 
}
```
InnoDB는 자주 사용되는 B-Tree 조회 패턴을 감지해서 메모리에 **해시 인덱스를 자동으로** 만들어줍니다.
```
B-Tree 인덱스: 루트 → 브랜치 → 리프 (여러 단계) 
해시 인덱스: 키 값 → 바로 데이터 페이지 (1단계) 
```

**언제 만들어질까요?**
기본적으로 다음 조건을 만족하면 생성됩니다:
- 동일한 인덱스
- 동일한 컬럼
- 동일한 조건
- 짧은 시간에 반복적으로 조회

### 동시성 충돌 - MVCC 개념의 등장
수천명이 동시에 접속하는 서비스를 운영한다고 가정해보겠습니다
```sql
-- 트랜잭션 A
BEGIN;
UPDATE live_rooms SET title = '새로운 제목' WHERE room_id = 100;
-- 아직 COMMIT 안 함 (고민 중...)

-- 동시에 실행되는 트랜잭션 B (시청자가 방송 목록 조회)
SELECT title FROM live_rooms WHERE room_id = 100;
```
트랜잭션 B는 A가 COMMIT할 때까지 기다려야 할까요?
만약 기다려야 한다면: 한 명이 수정하는 동안 수천 명이 읽기를 못 하고 서비스가 사실상 마비됨
만약 기다리지 않는다면: 아직 확정되지 않은 데이터를 읽게 됨 (Dirty Read) 롤백되면 잘못된 데이터를 본 것.


이를 해결하기 위해 InnoDB는 데이터의 여러 버전을 동시에 유지합니다.
```sql
INSERT INTO member (m_id, m_name, m_area) VALUES (12, '홍길동', '서울');
-- 이때 버퍼 풀에 데이터가 저장됩니다:

[버퍼 풀]
member 테이블 m_id=12: m_name='홍길동', m_area='서울'
```

이제 누군가 데이터를 수정합니다:
```sql
UPDATE member SET m_area = '경기' WHERE m_id = 12;
-- 아직 COMMIT 안 함
```

이 순간 무슨 일이 일어날까요?
```
[버퍼 풀]
member 테이블 m_id=12: m_area = '경기' (최신 버전, 아직 커밋 안 됨)
    ↓
[언두 로그]  
member 테이블 m_id=12: m_area = '서울' (변경 전 버전 백업)
```
InnoDB는 변경 전 데이터를 언두 로그에 백업해둡니다!
이제 다른 트랜잭션이 데이터를 조회하면:
```sql
SELECT m_area FROM member WHERE m_id = 12;
```
어떤 값을 반환할까요? 트랜잭션 격리 레벨에 따라 다릅니다:

READ UNCOMMITTED: 버퍼 풀의 최신 데이터 → '경기' (커밋 안 된 것도 봄)
READ COMMITTED 이상: 언두 로그의 커밋된 데이터 → '서울' (안전한 데이터만 봄)

#### 언두 로그
InnoDB는 격리 수준을 보장하기 위해 DML로 변경되기 이전 버전의 데이터를 별도로 백업하는데, 이를 **언두 로그**라고 합니다.

1. 트랜잭션 보장 (롤백)

```sql
BEGIN;
UPDATE member SET name='홍길동' WHERE member_id = 1;
-- 아직 COMMIT 안 함

이 순간:
[데이터 파일] name = '홍길동' (이미 변경됨!)
[언두 로그] name = 'bysu' (이전 값 백업)
```
트랜잭션이 실행되면 커밋하지 않아도 **실제 데이터 파일은 즉시 변경**됩니다. 'bysu'라는 이전 이름은 언두 로그에 백업됩니다.
- **커밋하면**: 현재 상태('홍길동')가 확정됨
- **롤백하면**: 언두 로그의 백업 데이터('bysu')를 데이터 파일로 복구

2. 격리 수준 보장 (MVCC)
   앞서 설명한 것처럼, 다른 트랜잭션이 커밋되지 않은 변경사항을 보지 않도록 언두 로그의 이전 버전을 제공합니다.


### 교착 상태(Dead Lock)
```sql
-- 트랜잭션 A
BEGIN;
UPDATE users SET balance = balance - 1000 WHERE id = 1; -- users:1 잠금 획득
-- 잠시 대기...
UPDATE orders SET status = 'paid' WHERE id = 1; -- orders:1 잠금 필요 (대기 중...)

-- 동시에 트랜잭션 B
BEGIN;
UPDATE orders SET status = 'processing' WHERE id = 1; -- orders:1 잠금 획득
-- 잠시 대기...
UPDATE users SET balance = balance + 1000 WHERE id = 1; -- users:1 잠금 필요 (대기 중...)
```
A는 B가 가진 잠금을 기다리고, B는 A가 가진 잠금을 기다립니다.

이를 해결하기 위해 InnoDB는 잠금 대기 목록을 그래프 형태로 관리하며 순환 구조를 감지합니다.
```
[잠금 대기 그래프]
A → (orders:1 대기) → B
B → (users:1 대기) → A
↑___________________↓
     순환 감지!
```

데드락이 감지되면 InnoDB는 언두 로그 레코드를 적게 가진 트랜잭션(롤백 비용이 작은 쪽)을 자동으로 종료시켜 교착 상태를 해결합니다.

### 휘발성 메모리 - WAL(Write-Ahead-Logging) 등장
버퍼 풀 덕분에 빠른 읽기와 쓰기는 가능합니다. 하지만 버퍼 풀의 모든 데이터를 휘발성인 RAM에 존재합니다. Dirty Page에 변경되어야 할 데이터가 저장되어 있는데 갑자기 정전이 나면 어떻게 될까요 ?

버퍼 풀의 Dirty Page는 아직 디스크에 쓰지 않았는데, 전부 사라져버립니다. 이를 해결하기 위해 WAL(Write-Ahead Logging)을 이용합니다. 즉, 데이터를 디스크에 쓰기 전에 로그를 먼저 씁니다.

```
실제 쓰기 순서:

1. 리두 로그에 "users 테이블 id=1의 balance를 +10000" 기록 (디스크 순차 쓰기, 빠름!)
2. 버퍼 풀에서 페이지 수정 (메모리 작업, Dirty Page 표시)
3. "커밋 완료" 응답 ✨
4. 나중에 체크포인트 시점에 디스크에 실제 페이지 반영
```
로그에 남기는 것도 디스크 쓰기 아닌가요 ?
- **리두 로그**: 순차적으로 append만 하므로 매우 빠름 (순차 I/O)
- **데이터 페이지**: 랜덤 위치에 써야 해서 느림 (랜덤 I/O)



### 리두 로그의 원형 구조

리두 로그는 고정된 크기로 원형 구조로 재사용됩니다:
```
[리두 로그 - 원형 구조]
┌─────────────────────────┐
│ 활성 리두 로그             │ ← 아직 디스크에 반영 안 됨
│ (체크포인트 필요)           │
├─────────────────────────┤
│ 덮어쓸 수 있는 영역         │ ← 이미 디스크에 반영됨
│ (재사용 가능)              │
└─────────────────────────┘
```
InnoDB는 주기적으로 **체크포인트**를 발생시켜 리두 로그의 변경사항을 실제 데이터 페이지로 디스크에 반영합니다. 체크포인트가 완료되면 그 부분의 리두 로그는 덮어쓸 수 있게 됩니다.


**리두 로그 크기를 어떻게 설정해야 할까요?**

너무 작으면:
```
[100MB 리두 로그]
쓰기 작업이 많음 → 금방 참 → 체크포인트 발생!
→ Dirty Page를 디스크에 급하게 Flush
→ 또 금방 참 → 또 체크포인트!
→ 계속 반복... 😢
```
- 체크포인트가 너무 자주 발생
- Dirty Page Flush가 빈번해져 쓰기 성능 저하

너무 크면:
```
[10GB 리두 로그]
쓰기 작업이 많음 → 오랫동안 쌓임 → 체크포인트 발생!
→ 수 GB의 Dirty Page를 한 번에 Flush
→ 순간적인 I/O 폭주 😢
→ 장애 시 10GB 로그를 재생해야 함 (복구 시간 증가) 😢
```

